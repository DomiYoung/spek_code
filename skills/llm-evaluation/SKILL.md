# LLM 评估技能

> 使用 LLM 作为评判者的生产级评估技术

---

## 触发条件

当用户提到以下内容时激活：
- "LLM-as-Judge"、"模型输出对比"、"评估 Rubric"
- "直接评分"、"成对比较"、"位置偏差"
- "评估流水线"、"自动质量评估"

---

## 核心概念

### 评估方法分类

| 方法 | 适用场景 | 可靠性 | 失败模式 |
|------|----------|--------|----------|
| **直接评分** | 客观标准（事实准确性、指令遵循） | 中-高 | 分数漂移、量表解释不一致 |
| **成对比较** | 主观偏好（语气、风格、说服力） | 高于直接评分 | 位置偏差、长度偏差 |

**关键洞察**：成对比较在偏好评估上与人类判断一致性更高，而直接评分适用于有明确真值的客观标准。

---

## 偏差图谱

LLM 评判者存在系统性偏差，必须主动缓解：

| 偏差类型 | 表现 | 缓解方法 |
|----------|------|----------|
| **位置偏差** | 第一位置响应获得偏好 | 交换位置二次评估，多数投票 |
| **长度偏差** | 更长响应得分更高 | 明确提示忽略长度，长度归一化 |
| **自我增强偏差** | 模型给自己输出打高分 | 使用不同模型生成和评估 |
| **冗长偏差** | 详细解释得分更高（即使不必要） | 特定标准 Rubric 惩罚无关细节 |
| **权威偏差** | 自信语气得分更高 | 要求引用证据，事实核查层 |

---

## 直接评分实现

### 三要素
1. **清晰标准** - 明确测量什么
2. **校准量表** - 1-3（二元+中性）/ 1-5（标准 Likert）/ 1-10（需详细 Rubric）
3. **结构化输出** - JSON 格式

### Prompt 模板

```
你是专业评估者，评估响应质量。

## 任务
根据每个标准评估以下响应。

## 原始提示
{prompt}

## 待评估响应
{response}

## 评估标准
{criteria_list}

## 指令
对每个标准：
1. 在响应中找到具体证据
2. 根据 Rubric 打分（1-{max} 量表）
3. 用证据支持你的分数
4. 建议一个具体改进点

## 输出格式
返回包含分数、理由和摘要的 JSON。
```

**关键**：所有评分 Prompt 必须要求先给出理由再给分数。研究表明这比"先分数"方法提高 15-25% 可靠性。

---

## 成对比较实现

### 位置偏差缓解协议

```
第一轮：响应 A 在前，响应 B 在后 → 记录结果
第二轮：响应 B 在前，响应 A 在后 → 记录结果
一致性检查：若两轮不一致 → 返回 TIE，降低置信度
最终结论：一致的获胜者 + 平均置信度
```

### Prompt 模板

```
你是专业评估者，比较两个 AI 响应。

## 关键指令
- 不要因为响应更长就偏好它
- 不要根据位置（前/后）偏好
- 仅根据指定标准关注质量
- 当响应真正等效时可以判定平局

## 原始提示
{prompt}

## 响应 A
{response_a}

## 响应 B
{response_b}

## 比较标准
{criteria_list}

## 输出格式
JSON：包含每标准比较、总体获胜者、置信度(0-1)和推理。
```

---

## Rubric 生成

良好定义的 Rubric 比开放式评分减少 40-60% 评估方差。

### Rubric 组件

| 组件 | 说明 |
|------|------|
| **等级描述** | 每个分数等级的清晰边界 |
| **特征** | 定义每个等级的可观察特征 |
| **示例** | 每个等级的代表性文本 |
| **边缘情况** | 模糊情况的指导 |
| **评分指南** | 一致应用的通用原则 |

### 严格度校准

- **宽松**：通过门槛较低，适合鼓励迭代
- **平衡**：公平、典型期望，适合生产使用
- **严格**：高标准，适合安全关键评估

---

## 评估流水线设计

```
┌─────────────────────────────────────────┐
│           评估流水线架构                  │
├─────────────────────────────────────────┤
│  输入: 响应 + 提示 + 上下文               │
│         │                               │
│         ▼                               │
│  ┌──────────────┐                       │
│  │  标准加载器   │ ◄── Rubrics, 权重     │
│  └──────┬───────┘                       │
│         ▼                               │
│  ┌──────────────┐                       │
│  │  主评分器    │ ◄── 直接/成对          │
│  └──────┬───────┘                       │
│         ▼                               │
│  ┌──────────────┐                       │
│  │  偏差缓解    │ ◄── 位置交换等         │
│  └──────┬───────┘                       │
│         ▼                               │
│  ┌──────────────┐                       │
│  │  置信度评分  │ ◄── 校准               │
│  └──────┬───────┘                       │
│         ▼                               │
│  输出: 分数 + 理由 + 置信度               │
└─────────────────────────────────────────┘
```

---

## 决策框架

```
是否有客观真值？
├── 是 → 直接评分
│   └── 例：事实准确性、指令遵循、格式合规
│
└── 否 → 是偏好或质量判断？
    ├── 是 → 成对比较
    │   └── 例：语气、风格、说服力、创意
    │
    └── 否 → 考虑参考基准评估
        └── 例：摘要（对比原文）、翻译（对比参考）
```

---

## 规模化评估

| 策略 | 说明 | 适用场景 |
|------|------|----------|
| **LLM 评审团 (PoLL)** | 多模型作为评判者，聚合投票 | 高风险决策 |
| **分层评估** | 便宜模型筛选，昂贵模型处理边缘情况 | 大批量处理 |
| **人机协作** | 自动评估清晰案例，人工审查低置信度 | 关键应用 |

---

## 常见反模式

| 反模式 | 问题 | 解决方案 |
|--------|------|----------|
| 无理由评分 | 分数缺乏依据，难以调试 | 始终要求证据支持的理由 |
| 单轮成对比较 | 位置偏差污染结果 | 始终交换位置检查一致性 |
| 标准过载 | 测量多个方面的标准不可靠 | 一个标准 = 一个可测量方面 |
| 缺少边缘指导 | 评估者处理模糊情况不一致 | Rubric 中包含边缘情况 |
| 忽略置信度校准 | 高置信度错误判断更糟 | 校准置信度到位置一致性 |

---

## 实践指南

1. **始终要求先理由后分数** - 提高 15-25% 可靠性
2. **成对比较必须交换位置** - 单轮被位置偏差污染
3. **量表粒度匹配 Rubric 细节** - 1-10 需要详细等级描述
4. **分离客观和主观标准** - 客观用直接评分，主观用成对比较
5. **包含置信度分数** - 校准到位置一致性和证据强度
6. **显式定义边缘情况** - 模糊情况造成最大评估方差
7. **使用领域特定 Rubric** - 通用 Rubric 产生通用（不太有用）评估
8. **对照人类判断验证** - 自动评估仅在与人类评估相关时有价值
9. **监控系统性偏差** - 按标准、响应类型、模型跟踪分歧模式
10. **设计迭代改进** - 评估系统通过反馈循环改进

---

## 与 Spec-Kit 整合

### 在 speckit.implement 阶段使用

当实现需要质量验证时：
1. 定义验收标准作为评估 Rubric
2. 使用直接评分验证客观要求
3. 使用成对比较选择最佳实现方案

### 与 Context Engineering 关系

- 评估 Prompt 需要良好的上下文结构（参见 `context-fundamentals`）
- 评估 Prompt 可优化 Token 效率（参见 `context-optimization`）
- 长对话中的评估需要抗衰减锚点（参见 `context-degradation`）

---

## 参考资料

- [LLM-as-Judge 研究 (Zheng et al., 2023)](https://arxiv.org/abs/2306.05685)
- [G-Eval: 使用 GPT-4 评估 NLG (Liu et al., 2023)](https://arxiv.org/abs/2303.16634)
- [LLM 不是公平评估者 (Wang et al., 2023)](https://arxiv.org/abs/2305.17926)
